{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libs\n",
    "import hashlib\n",
    "import os\n",
    "import shutil\n",
    "import stat\n",
    "import argparse\n",
    "import re\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party dependencies\n",
    "import filetype\n",
    "import mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stat import S_IREAD, S_IRGRP, S_IROTH\n",
    "\n",
    "TS_MULT = 10**9\n",
    "BLOCKLENGTH = 262144\n",
    "\n",
    "def make_file_read_only(path):\n",
    "    os.chmod(path, S_IREAD|S_IRGRP|S_IROTH)\n",
    "        \n",
    "def open_file(root_path, name, temp_path=None):\n",
    "    if not temp_path:\n",
    "        temp_path = root_path\n",
    "        \n",
    "    if name.startswith('.'):\n",
    "        #we ignore files starting with a dot when inspecting\n",
    "        #the stash, so we don't want to use such a name for a\n",
    "        #file we care about\n",
    "        name = '_'+name\n",
    "    \n",
    "    temp_file_name = datetime.now().strftime('%Y%m%d%H%M%S%f')\n",
    "    temp_file_path = os.path.join(temp_path, temp_file_name)\n",
    "    temp_file = open(temp_file_path, 'wb')\n",
    "    return {'file': temp_file,\n",
    "            'name': name,\n",
    "            'root_path': root_path,\n",
    "            'temp_file_path': temp_file_path,\n",
    "            'hasher': hashlib.sha256(),\n",
    "            'hashing_started': int(datetime.now().timestamp()*TS_MULT),\n",
    "            'bytes_hashed': 0}\n",
    "\n",
    "def write_to_file(record, data):\n",
    "    record['file'].write(data)\n",
    "    record['hasher'].update(data)\n",
    "    record['bytes_hashed'] = record['bytes_hashed'] + len(data)\n",
    "\n",
    "def abort_file(record):\n",
    "    record['file'].close()\n",
    "    os.remove(record['temp_file_path'])\n",
    "\n",
    "def save_file(record):\n",
    "    record['file'].close()\n",
    "    sha256 = record['hasher'].hexdigest()\n",
    "    record['sha256'] = sha256\n",
    "    record['hashing_completed'] = int(datetime.now().timestamp()*TS_MULT)\n",
    "\n",
    "    del record['file']\n",
    "    del record['hasher']\n",
    "\n",
    "    new_dir_path = hash2path(record['root_path'], sha256)\n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.makedirs(new_dir_path)\n",
    "        new_file_path = os.path.join(new_dir_path, record['name'])\n",
    "        shutil.move(record['temp_file_path'], new_file_path)\n",
    "        make_file_read_only(new_file_path)\n",
    "        record['new'] = True\n",
    "    else: #data is already in hash store\n",
    "        os.remove(record['temp_file_path'])\n",
    "        record['new'] = False\n",
    "        \n",
    "\n",
    "def hash_file(path):\n",
    "    hash_rec = {}\n",
    "    hasher = hashlib.sha256()\n",
    "    byte_count = 0\n",
    "    hash_rec['hashing_started'] = int(datetime.now().timestamp()*TS_MULT)\n",
    "    with open(path, 'rb') as fb:\n",
    "        byte_block = fb.read(BLOCKLENGTH)\n",
    "        while len(byte_block) > 0:\n",
    "            byte_count = byte_count + len(byte_block)\n",
    "            hasher.update(byte_block)\n",
    "            byte_block = fb.read(BLOCKLENGTH)\n",
    "    hash_rec['sha256'] = hasher.hexdigest()\n",
    "    hash_rec['hashing_completed'] = int(datetime.now().timestamp()*TS_MULT)\n",
    "    hash_rec['bytes_hashed'] = byte_count\n",
    "    \n",
    "    return hash_rec\n",
    "        \n",
    "def move_file(root_path, file_path):\n",
    "    hash_rec = hash_file(file_path)\n",
    "    new_dir_path = hash2path(root_path, hash_rec['sha256'])\n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.makedirs(new_dir_path)\n",
    "        name = os.path.basename(file_path)\n",
    "        new_file_path = os.path.join(new_dir_path, name)\n",
    "        shutil.move(file_path, new_file_path)\n",
    "        make_file_read_only(new_file_path)\n",
    "        hash_rec['new'] = True\n",
    "    else:\n",
    "        #file already exists\n",
    "        hash_rec['new'] = False\n",
    "    return hash_rec\n",
    "\n",
    "def check_file(root_path, hsh, num_bytes=False):\n",
    "    path = hash2filepath(root_path, hsh)\n",
    "    if not path:\n",
    "        return False\n",
    "    hasher = hashlib.sha256()\n",
    "    byte_count = 0\n",
    "    with open(path, 'rb') as fb:\n",
    "        byte_block = fb.read(BLOCKLENGTH)\n",
    "        while len(byte_block) > 0:\n",
    "            byte_count = byte_count + len(byte_block)\n",
    "            hasher.update(byte_block)\n",
    "            byte_block = fb.read(BLOCKLENGTH)\n",
    "    sha256 = hasher.hexdigest()\n",
    "    if hsh != sha256:\n",
    "        print('hash does not match:')\n",
    "        print('record_hash={}'.format(hsh))\n",
    "        print('stored_hash={}'.format(sha256))\n",
    "        return False\n",
    "    if num_bytes and (num_bytes != byte_count):\n",
    "        print('num bytes does not match:')\n",
    "        print('record={}'.format(num_bytes))\n",
    "        print('stored={}'.format(byte_count))\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def delete_file(root_path, hsh):\n",
    "    dir_path = hash2path(root_path, hsh)\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('directory {} does not exist'.format(dir_path))\n",
    "        return False\n",
    "    \n",
    "    for f in os.listdir(dir_path):\n",
    "        if not os.path.isfile(os.path.join(dir_path, f)):\n",
    "            print('directory {} contains something other than '\n",
    "                  'a regular file'.format(dir_path))\n",
    "            print(os.path.join(dir_path, f))\n",
    "            return False\n",
    "    \n",
    "    for f in os.listdir(dir_path):\n",
    "        os.remove(os.path.join(dir_path, f))\n",
    "        \n",
    "    os.removedirs(dir_path)\n",
    "    return True\n",
    "\n",
    "\n",
    "def path2hash(root_path, path):\n",
    "    #container dir path to hash\n",
    "    rp = os.path.relpath(path, start=root_path)\n",
    "    return ''.join(os.path.normpath(rp).split(os.path.sep))\n",
    "\n",
    "def hash2path(root_path, hsh):\n",
    "    #hash to container dir path\n",
    "    parts = (hsh[0:2], hsh[2:4], hsh[4:6], hsh[6:8], hsh[8:])\n",
    "    return os.path.join(root_path, *parts)\n",
    "\n",
    "def hash2filepath(root_path, hsh):\n",
    "    dir_path = hash2path(root_path, hsh)\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('directory {} does not exist'.format(dir_path))\n",
    "        return False\n",
    "    \n",
    "    # we ignore files starting with a dot e.g. .DS_Store\n",
    "    ls = [f for f in os.listdir(dir_path) if not f.startswith('.')]\n",
    "    \n",
    "    if len(ls) == 0:\n",
    "        print('directory exists but is empty')\n",
    "        return False\n",
    "    if len(ls) > 1:\n",
    "        print('directory exists but contains more than one file!')\n",
    "        return False\n",
    "    return os.path.join(dir_path, ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCKLENGTH = 262144 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff to do Boolean queries\n",
    "\n",
    "ATOM = 0\n",
    "NOT = 1\n",
    "OR = 2\n",
    "AND = 3\n",
    "\n",
    "class P(object):\n",
    "    def __init__(self, *args, kind=ATOM):\n",
    "        self.kind = kind\n",
    "        self.args = args\n",
    "\n",
    "    def __invert__(self):\n",
    "        return P(self, kind=NOT)\n",
    "    \n",
    "    def __or__(self, other):\n",
    "        return P(self, other, kind=OR)\n",
    "    \n",
    "    def __and__(self, other):\n",
    "        return P(self, other, kind=AND)\n",
    "    \n",
    "    def to_str(self, atom_fun):\n",
    "        if self.kind == ATOM:\n",
    "            return atom_fun(self.args[0])\n",
    "        if self.kind == NOT:\n",
    "            return 'NOT {}'.format(self.args[0].to_str(atom_fun))\n",
    "        if self.kind == OR:\n",
    "            return '({} OR {})'.format(self.args[0].to_str(atom_fun), self.args[1].to_str(atom_fun))\n",
    "        if self.kind == AND:\n",
    "            return '({} AND {})'.format(self.args[0].to_str(atom_fun), self.args[1].to_str(atom_fun))  \n",
    "\n",
    "def build_tag_query(p):\n",
    "    atoms = {}\n",
    "    atom_count = 1\n",
    "    \n",
    "    def walk(p):\n",
    "        nonlocal atom_count\n",
    "        nonlocal atoms\n",
    "        if p.kind == ATOM:\n",
    "            atoms[p.args[0]] = atom_count\n",
    "            atom_count += 1\n",
    "        else:\n",
    "            for a in p.args:\n",
    "                walk(a)\n",
    "    \n",
    "    walk(p)\n",
    "                \n",
    "    def atom_fun(a):\n",
    "        return 'hash IN pred{}'.format(atoms[a])\n",
    "    \n",
    "    subqs = []\n",
    "    params = []\n",
    "    #need to check k[1] for safety here...\n",
    "    for k, v in atoms.items():\n",
    "        subqs.append('pred{} AS (SELECT hash FROM Tag WHERE key = ? AND value {} ?)'.format(v, k[1]))\n",
    "        params.extend([k[0], k[2]])\n",
    "    \n",
    "    query = 'WITH {} SELECT * FROM Data WHERE {}'.format(', '.join(subqs), p.to_str(atom_fun))\n",
    "    return (query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashStash():\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "        if not os.path.exists(db_path):\n",
    "            print('no file at {}. '\n",
    "                  'creating a new database here.'.format(db_path))\n",
    "            self.init_db()\n",
    "        else:\n",
    "            self.conn = sqlite3.connect(db_path)\n",
    "            \n",
    "    def __del__(self):\n",
    "        self.conn.close()\n",
    "            \n",
    "    def init_db(self):\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('CREATE TABLE Data ('\n",
    "                  'hash TEXT NOT NULL, '\n",
    "                  'num_bytes INT, '\n",
    "                  'media_type TEXT, '\n",
    "                  'title TEXT, '\n",
    "                  'PRIMARY KEY (hash) );')\n",
    "        self.conn.commit()\n",
    "        c.execute('CREATE TABLE HashStore ('\n",
    "                  'id INTEGER NOT NULL PRIMARY KEY, '\n",
    "                  'name TEXT UNIQUE, '\n",
    "                  'root_path TEXT UNIQUE );')\n",
    "        self.conn.commit()\n",
    "        c.execute('CREATE TABLE Copy ('\n",
    "                  'hash TEXT NOT NULL, '\n",
    "                  'store_id INT, '\n",
    "                  'FOREIGN KEY(hash) REFERENCES Data(hash), '\n",
    "                  'FOREIGN KEY(store_id) REFERENCES HashStore(id), '\n",
    "                  'UNIQUE(hash, store_id) );')\n",
    "        self.conn.commit()\n",
    "        c.execute('CREATE TABLE Source ('\n",
    "                  'hash TEXT NOT NULL, '\n",
    "                  'description TEXT NOT NULL, '\n",
    "                  'mtime_ns INT, '\n",
    "                  'ctime_ns INT, '\n",
    "                  'hashing_started INT NOT NULL, '\n",
    "                  'hashing_completed INT NOT NULL, '\n",
    "                  'FOREIGN KEY (hash) REFERENCES Data(hash) );')\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        \n",
    "    def add_store(self, root_path, name):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('INSERT INTO HashStore (name, root_path) '\n",
    "                  'VALUES (?, ?)', (name, root_path))\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        \n",
    "    def get_store_info(self, store_name):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('SELECT id, root_path FROM HashStore '\n",
    "                  'WHERE name = ?', (store_name,))\n",
    "        rows = c.fetchall()\n",
    "        if len(rows) == 0:\n",
    "            print('no store with name {}'.format(store_name))\n",
    "            return None\n",
    "        if len(rows) > 1:\n",
    "            print('unexpected: more than one '\n",
    "                  'store with name {}'.format(store_name))\n",
    "            return None\n",
    "        return rows[0] #(id, root_path)\n",
    "        \n",
    "    def add_file(self, file_path,\n",
    "                 store_name='default', move=True):\n",
    "        store_id, store_root_path = self.get_store_info(store_name)\n",
    "        path = os.path.abspath(file_path)\n",
    "        name = os.path.basename(path)\n",
    "        \n",
    "        mtime = os.stat(path).st_mtime_ns\n",
    "        ctime = os.stat(path).st_ctime_ns\n",
    "        \n",
    "        if move:\n",
    "            # move the file in\n",
    "            hash_rec = move_file(store_root_path, file_path)\n",
    "        else:\n",
    "            # copy mode\n",
    "            hash_rec = open_file(store_root_path, name)\n",
    "            with open(path, 'rb') as f:\n",
    "                datablock = f.read(BLOCKLENGTH)\n",
    "                while len(datablock) > 0:\n",
    "                    write_to_file(hash_rec, datablock)\n",
    "                    datablock = f.read(BLOCKLENGTH)\n",
    "        \n",
    "            mtime_2 = os.stat(path).st_mtime_ns\n",
    "            if mtime_2 != mtime:\n",
    "                # file modified while we were hashing it\n",
    "                # it is possible that this method doesn't\n",
    "                # detect modification\n",
    "                # e.g. mod1...start hash...mod2...end hash\n",
    "                # but time(mod1) = time(mod2) at the available\n",
    "                # resolution - which is one second for some FS\n",
    "                print('ABORTED. The file at {} '\n",
    "                      'was modified while we were '\n",
    "                      'computing its hash'.format(path))\n",
    "                abort_file(hash_rec)\n",
    "                return None\n",
    "            else:\n",
    "                save_file(hash_rec)\n",
    "        \n",
    "        sha256 = hash_rec['sha256']\n",
    "            \n",
    "        c = self.conn.cursor()\n",
    "        c.execute('SELECT hash FROM Data '\n",
    "                  'WHERE hash = ?',\n",
    "                  (sha256,))\n",
    "        rows = c.fetchall()\n",
    "        if len(rows) == 0:\n",
    "            # the hash is not currently in our DB\n",
    "\n",
    "            # get media type\n",
    "            p = hash2filepath(store_root_path, sha256)\n",
    "            media_type = filetype.guess_mime(p)\n",
    "\n",
    "            c.execute('INSERT INTO Data '\n",
    "                      '(hash, num_bytes, media_type, title) '\n",
    "                      'VALUES (?, ?, ?, ?);',\n",
    "                      (sha256, hash_rec['bytes_hashed'],\n",
    "                       media_type, name))\n",
    "\n",
    "        c.execute('SELECT hash FROM Copy '\n",
    "                  'WHERE hash = ? AND store_id = ?',\n",
    "                  (sha256, store_id))\n",
    "        rows = c.fetchall()\n",
    "        if len(rows) == 0:\n",
    "            # DB has no record of this copy\n",
    "            c.execute('INSERT INTO Copy (hash, store_id) '\n",
    "                      'VALUES (?, ?);',\n",
    "                      (sha256, store_id))\n",
    "\n",
    "        c.execute('INSERT INTO Source '\n",
    "                  '(hash, description,'\n",
    "                  ' mtime_ns, ctime_ns,'\n",
    "                  ' hashing_started,'\n",
    "                  ' hashing_completed) '\n",
    "                  'VALUES (?, ?, ?, ?, ?, ?)',\n",
    "                  (sha256, path,\n",
    "                   mtime, ctime,\n",
    "                   hash_rec['hashing_started'],\n",
    "                   hash_rec['hashing_completed']))\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        return sha256\n",
    "    \n",
    "    def create_tag_table(self):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('CREATE TABLE Tag '\n",
    "                  '(hash TEXT, '\n",
    "                   'key TEXT, '\n",
    "                   'value TEXT, '\n",
    "                   'FOREIGN KEY (hash) REFERENCES Data(hash) )')\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "    \n",
    "    def add_tag(self, hsh, key, value):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('INSERT INTO Tag (hash, key, value) VALUES (?, ?, ?)',\n",
    "                  (hsh, key, value))\n",
    "        conn.commit()\n",
    "        del c\n",
    "        \n",
    "    def get_path(self, hsh):\n",
    "        store_id, store_root_path = self.get_store_info('default')\n",
    "        return hash2filepath(store_root_path, hsh) #\n",
    "        \n",
    "    def add_tags(self, hsh, tag_fn):\n",
    "        tags = tag_fn(self.get_path(hsh))\n",
    "        c = self.conn.cursor()\n",
    "        c.executemany('INSERT INTO Tag (hash, key, value) VALUES (?, ?, ?)',\n",
    "                      [(hsh, k, v) for k, v in tags])\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        \n",
    "    def delete_sources(self, hsh):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('DELETE FROM Source WHERE hash = ?', (hsh,))\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        \n",
    "    def delete_copy(self, hsh, store_name):\n",
    "        store_id, store_root_path = self.get_store_info(store_name)\n",
    "        \n",
    "        c = self.conn.cursor()\n",
    "        c.execute('DELETE FROM Copy WHERE hash = ? AND store_id = ?',\n",
    "                  (hsh, store_id))\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        delete_file(store_root_path, hsh)\n",
    "        \n",
    "    def delete_hash(self, hsh):\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('SELECT '\n",
    "                  'Copy.store_id, name, root_path '\n",
    "                  'FROM Copy JOIN HashStore '\n",
    "                  'ON Copy.store_id = id '\n",
    "                  'WHERE Copy.hash = ?', (hsh,))\n",
    "        rows = c.fetchall()\n",
    "        if len(rows) > 0:\n",
    "            print('There are copies of this hash the stores:')\n",
    "            for r in rows:\n",
    "                print('{} (id:{}) @ {}'.format(r[1],r[0],r[2]))\n",
    "            return False\n",
    "        c.execute('DELETE FROM Data WHERE hash = ?', (hsh,))\n",
    "        self.conn.commit()\n",
    "        del c\n",
    "        return True\n",
    "        \n",
    "    def check_integrity_of_store(self, store_name):\n",
    "        store_id, store_root_path = self.get_store_info(store_name)\n",
    "        \n",
    "        c = self.conn.cursor()\n",
    "        c.execute('SELECT hash FROM Copy WHERE store_id = ?',\n",
    "                  (store_id,))\n",
    "        REC_LIMIT = 1000\n",
    "        row_block = c.fetchmany(REC_LIMIT)\n",
    "        i = 0\n",
    "        while len(row_block) > 0:\n",
    "            print(i)\n",
    "            i = i+1\n",
    "            for r in row_block:\n",
    "                is_good = check_file(store_root_path, r[0])\n",
    "                if not is_good:\n",
    "                    print('bad store of {}'.format(r[0]))\n",
    "            row_block = c.fetchmany(REC_LIMIT)\n",
    "    \n",
    "    def quick_paths(self, query, root=None):\n",
    "        if root==None:\n",
    "            _, root = self.get_store_info('default')\n",
    "        r = pd.read_sql(query, self.conn)\n",
    "        r['path'] = r['hash'].map(lambda h: hash2filepath(root, h))\n",
    "        return r\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(x):\n",
    "    if type(x) == mutagen.mp4.MP4FreeForm:\n",
    "        return x.decode()\n",
    "    return str(x)\n",
    "\n",
    "def dict_to_tags(d, key_prefix=''):\n",
    "    tag_list = []\n",
    "    for k, v in d.items():\n",
    "        if type(v) == list:\n",
    "            for i in v:\n",
    "                tag_list.append((key_prefix+k, to_str(i)))\n",
    "        else:\n",
    "            tag_list.append((key_prefix+k, to_str(v)))\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAC tagging\n",
    "from mutagen import flac as mflac\n",
    "\n",
    "def flac_tags(file_path):\n",
    "    f = mflac.FLAC(file_path)\n",
    "    f_flat = dict_to_tags(dict(f), key_prefix='flac:')\n",
    "    return f_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP4 tagging\n",
    "from mutagen import mp4 as mmp4\n",
    "\n",
    "def mp4_tags(file_path):\n",
    "    m = mmp4.MP4(file_path)\n",
    "    m_flat = dict_to_tags(dict(m), key_prefix='mp4:')\n",
    "    return m_flat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP3 tagging\n",
    "from mutagen import mp3 as mmp3\n",
    "\n",
    "def mp3_tags(file_path):\n",
    "    m = mmp3.MP3(file_path)\n",
    "    tags = []\n",
    "    for k, v in dict(m).items():\n",
    "        if k.startswith('PRIV'):\n",
    "            continue\n",
    "        for subv in getattr(v, 'text', []):\n",
    "            tags.append(('id3:'+k, str(subv)))     \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hashes_full(hash_list):\n",
    "    for hsh in hash_list:\n",
    "        print(hsh)\n",
    "        hs.delete_sources(hsh)\n",
    "        hs.delete_copy(hsh, 'default')\n",
    "        hs.delete_hash(hsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_recurse(path, func, *args, **kwargs):\n",
    "    for dirname, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                fp = os.path.join(dirname, file)\n",
    "                if command_args.verbose:\n",
    "                    print(fp)\n",
    "                r = func(fp, *args, **kwargs)\n",
    "                if command_args.verbose:\n",
    "                    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = HashStash('/home/william/md.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_args = lambda : None\n",
    "command_args.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    c = hs.conn.cursor()\n",
    "    c.execute('INSERT INTO Tag (hash, key, value) '\n",
    "              'SELECT hash, \"podcast\", value FROM Tag WHERE key = \"id3:PCST\"')\n",
    "    hs.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>num_bytes</th>\n",
       "      <th>media_type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca7a6bd9c1d7947eeaea3dae789aea484834fc7ef793a5...</td>\n",
       "      <td>13222501</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>Ryan Patrick Maguire - moDernisT.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2192dd5634d880af8576936ceb0f026e0f74e2feb6cb27...</td>\n",
       "      <td>3145728</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>20210219141549414447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00078e67daba3375fc335093b4540acb25b0096b8c4998...</td>\n",
       "      <td>3430003</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>15 Off the Beach (Spilling Coffee).mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00092329f004f36e27d1cea9360fd8c5816fc6d5a0154d...</td>\n",
       "      <td>9033808</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>05 Glitch.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c4f11952767e62f2d7fc0cdc8aafb1b1b6130bfd085...</td>\n",
       "      <td>22307302</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>1-18 DJ Food - The Breaks of Wrath.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00178511c4d32326e203af213b8aeee149d469230f616d...</td>\n",
       "      <td>6298257</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>06 Windscale 2.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001bcb305fb8e381e78bfe243097e9ae8b327f6b819eb4...</td>\n",
       "      <td>10498976</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>10 Hippy Death Suite.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001cb7d4a25c7772b62dd2eb1001ef3fae8629c7f438c7...</td>\n",
       "      <td>6677607</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>07 The Spiracles.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00273e61ebdc21ddad2e90bef7cc36b1ca6b33eed12bdc...</td>\n",
       "      <td>4273802</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>08 Victory Egg.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002e8dd45932564e671b7507210c72df8bb4d73bf2d351...</td>\n",
       "      <td>3248284</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>04 Oraphis yn Delphie.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hash  num_bytes    media_type  \\\n",
       "0  ca7a6bd9c1d7947eeaea3dae789aea484834fc7ef793a5...   13222501  audio/x-flac   \n",
       "1  2192dd5634d880af8576936ceb0f026e0f74e2feb6cb27...    3145728  audio/x-flac   \n",
       "2  00078e67daba3375fc335093b4540acb25b0096b8c4998...    3430003    audio/mpeg   \n",
       "3  00092329f004f36e27d1cea9360fd8c5816fc6d5a0154d...    9033808    audio/mpeg   \n",
       "4  000c4f11952767e62f2d7fc0cdc8aafb1b1b6130bfd085...   22307302  audio/x-flac   \n",
       "5  00178511c4d32326e203af213b8aeee149d469230f616d...    6298257    audio/mpeg   \n",
       "6  001bcb305fb8e381e78bfe243097e9ae8b327f6b819eb4...   10498976  audio/x-flac   \n",
       "7  001cb7d4a25c7772b62dd2eb1001ef3fae8629c7f438c7...    6677607    audio/mpeg   \n",
       "8  00273e61ebdc21ddad2e90bef7cc36b1ca6b33eed12bdc...    4273802    audio/mpeg   \n",
       "9  002e8dd45932564e671b7507210c72df8bb4d73bf2d351...    3248284    audio/mpeg   \n",
       "\n",
       "                                     title  \n",
       "0    Ryan Patrick Maguire - moDernisT.flac  \n",
       "1                     20210219141549414447  \n",
       "2   15 Off the Beach (Spilling Coffee).mp3  \n",
       "3                            05 Glitch.mp3  \n",
       "4  1-18 DJ Food - The Breaks of Wrath.flac  \n",
       "5                       06 Windscale 2.mp3  \n",
       "6                10 Hippy Death Suite.flac  \n",
       "7                     07 The Spiracles.mp3  \n",
       "8                       08 Victory Egg.mp3  \n",
       "9                04 Oraphis yn Delphie.mp3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('SELECT * FROM Data LIMIT 10', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = pd.read_sql('SELECT Data.hash, a.value as artist FROM '\n",
    "                    'Data LEFT JOIN (SELECT hash, value FROM Tag WHERE key = \"artist\") a '\n",
    "                    'ON Data.hash = a.hash '\n",
    "                    'WHERE Data.media_type LIKE \"audio/%\" ', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca7a6bd9c1d7947eeaea3dae789aea484834fc7ef793a5...</td>\n",
       "      <td>Ryan Patrick Maguire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2192dd5634d880af8576936ceb0f026e0f74e2feb6cb27...</td>\n",
       "      <td>μ-Ziq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00078e67daba3375fc335093b4540acb25b0096b8c4998...</td>\n",
       "      <td>Swell Maps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00092329f004f36e27d1cea9360fd8c5816fc6d5a0154d...</td>\n",
       "      <td>Autechre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c4f11952767e62f2d7fc0cdc8aafb1b1b6130bfd085...</td>\n",
       "      <td>DJ Food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hash                artist\n",
       "0  ca7a6bd9c1d7947eeaea3dae789aea484834fc7ef793a5...  Ryan Patrick Maguire\n",
       "1  2192dd5634d880af8576936ceb0f026e0f74e2feb6cb27...                 μ-Ziq\n",
       "2  00078e67daba3375fc335093b4540acb25b0096b8c4998...            Swell Maps\n",
       "3  00092329f004f36e27d1cea9360fd8c5816fc6d5a0154d...              Autechre\n",
       "4  000c4f11952767e62f2d7fc0cdc8aafb1b1b6130bfd085...               DJ Food"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = pd.read_sql('SELECT Data.hash, a.value as artist, b.value as album FROM '\n",
    "                    'Data JOIN (SELECT hash, value FROM Tag WHERE key = \"artist\") a '\n",
    "                    'ON Data.hash = a.hash '\n",
    "                    'JOIN (SELECT hash, value FROM Tag WHERE key = \"album\") b '\n",
    "                    'ON Data.hash = b.hash '\n",
    "                    'WHERE Data.media_type LIKE \"audio/%\" ', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>013b7c68c3d43cb37112257a7aa53754dd0a2d313247e2...</td>\n",
       "      <td>Deniece Williams</td>\n",
       "      <td>Footloose: 15th Anniversary Collector's Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01a9d1ba325b1d5af145843652d667e4d3cc8d5f4b2900...</td>\n",
       "      <td>Talking Heads</td>\n",
       "      <td>More Songs About Buildings and Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01eb1d88af840bd273528c220e5d817156c2e9a5d3b23a...</td>\n",
       "      <td>The Fall</td>\n",
       "      <td>Slates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02969752d01ad2fb103d884ac42da3e603687a089b6c73...</td>\n",
       "      <td>Talking Heads</td>\n",
       "      <td>Fear of Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03d18386b59fbcca4b42faede16e71b771b8e055d52e0a...</td>\n",
       "      <td>Beat Happening</td>\n",
       "      <td>Black Candy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10922</th>\n",
       "      <td>2083661abcaf6f148b105801934546c36995e176307fc1...</td>\n",
       "      <td>Grandaddy</td>\n",
       "      <td>A Pretty Mess By This One Band [EP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>20863bfc1a621a8517297b5692e7608d8e38af2d9801ce...</td>\n",
       "      <td>The Hospitals</td>\n",
       "      <td>I've Visited The Island Of Jocks and Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>20c9cb1b87ff366c25fbd9f977cb58b78a9e1f5c55479c...</td>\n",
       "      <td>Björk</td>\n",
       "      <td>Vespertine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>fb0fa5c8cee83b7d8130ea6021a507367701307a95cdad...</td>\n",
       "      <td>Ken and Andy and WFMU</td>\n",
       "      <td>Seven Second Delay with Ken and Andy Podcast |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>261bcfba01954fa88f7fe1775f998cef4760436408249f...</td>\n",
       "      <td>Tom Scharpling and WFMU</td>\n",
       "      <td>The Best Show on WFMU with Tom Scharpling | WFMU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10927 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    hash  \\\n",
       "0      013b7c68c3d43cb37112257a7aa53754dd0a2d313247e2...   \n",
       "1      01a9d1ba325b1d5af145843652d667e4d3cc8d5f4b2900...   \n",
       "2      01eb1d88af840bd273528c220e5d817156c2e9a5d3b23a...   \n",
       "3      02969752d01ad2fb103d884ac42da3e603687a089b6c73...   \n",
       "4      03d18386b59fbcca4b42faede16e71b771b8e055d52e0a...   \n",
       "...                                                  ...   \n",
       "10922  2083661abcaf6f148b105801934546c36995e176307fc1...   \n",
       "10923  20863bfc1a621a8517297b5692e7608d8e38af2d9801ce...   \n",
       "10924  20c9cb1b87ff366c25fbd9f977cb58b78a9e1f5c55479c...   \n",
       "10925  fb0fa5c8cee83b7d8130ea6021a507367701307a95cdad...   \n",
       "10926  261bcfba01954fa88f7fe1775f998cef4760436408249f...   \n",
       "\n",
       "                        artist  \\\n",
       "0             Deniece Williams   \n",
       "1                Talking Heads   \n",
       "2                     The Fall   \n",
       "3                Talking Heads   \n",
       "4               Beat Happening   \n",
       "...                        ...   \n",
       "10922                Grandaddy   \n",
       "10923            The Hospitals   \n",
       "10924                    Björk   \n",
       "10925    Ken and Andy and WFMU   \n",
       "10926  Tom Scharpling and WFMU   \n",
       "\n",
       "                                                   album  \n",
       "0        Footloose: 15th Anniversary Collector's Edition  \n",
       "1                    More Songs About Buildings and Food  \n",
       "2                                                 Slates  \n",
       "3                                          Fear of Music  \n",
       "4                                            Black Candy  \n",
       "...                                                  ...  \n",
       "10922                A Pretty Mess By This One Band [EP]  \n",
       "10923          I've Visited The Island Of Jocks and Jazz  \n",
       "10924                                         Vespertine  \n",
       "10925  Seven Second Delay with Ken and Andy Podcast |...  \n",
       "10926   The Best Show on WFMU with Tom Scharpling | WFMU  \n",
       "\n",
       "[10927 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = pd.read_sql('SELECT Data.hash, Data.title, a.value as artist, b.value as album, t.value as title FROM '\n",
    "                    'Data JOIN (SELECT hash, value FROM Tag WHERE key = \"artist\") a '\n",
    "                    'ON Data.hash = a.hash '\n",
    "                    'JOIN (SELECT hash, value FROM Tag WHERE key = \"album\") b '\n",
    "                    'ON Data.hash = b.hash '\n",
    "                    'JOIN (SELECT hash, value FROM Tag WHERE key = \"title\") t '\n",
    "                    'ON Data.hash = t.hash '\n",
    "                    'WHERE Data.media_type LIKE \"audio/%\" '\n",
    "                    'ORDER BY artist, album, title', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "music.to_csv('music.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH pred1 AS (SELECT hash FROM Tag WHERE key = ? AND value LIKE ?), pred2 AS (SELECT hash FROM Tag WHERE key = ? AND value LIKE ?) SELECT * FROM Data WHERE (hash IN pred1 AND hash IN pred2)\n",
      "['flac:artist', 'St%', 'flac:title', 'B%']\n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>num_bytes</th>\n",
       "      <th>media_type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02277212cd1397c19cebcd52c67ee6be8d99b09242320b...</td>\n",
       "      <td>27505122</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>11 Bop Scotch.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51c92d74f402a6b4ae99c2e58df6f12afc48f3d801333c...</td>\n",
       "      <td>13106644</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>01.Black_Ants_in_Sound-Dust.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b4d1daad3df6be36f0fe09c8225d69309d141f16b82c45...</td>\n",
       "      <td>22285863</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>03 Barock - Plastik.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e01febea9cd164ac46b918400905151d67bb2bf28aa745...</td>\n",
       "      <td>35686523</td>\n",
       "      <td>audio/x-flac</td>\n",
       "      <td>04.Baby_Lulu.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hash  num_bytes    media_type  \\\n",
       "0  02277212cd1397c19cebcd52c67ee6be8d99b09242320b...   27505122  audio/x-flac   \n",
       "1  51c92d74f402a6b4ae99c2e58df6f12afc48f3d801333c...   13106644  audio/x-flac   \n",
       "2  b4d1daad3df6be36f0fe09c8225d69309d141f16b82c45...   22285863  audio/x-flac   \n",
       "3  e01febea9cd164ac46b918400905151d67bb2bf28aa745...   35686523  audio/x-flac   \n",
       "\n",
       "                              title  \n",
       "0                11 Bop Scotch.flac  \n",
       "1  01.Black_Ants_in_Sound-Dust.flac  \n",
       "2          03 Barock - Plastik.flac  \n",
       "3                 04.Baby_Lulu.flac  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, params = build_tag_query(P(('flac:artist', 'LIKE', 'St%')) & \n",
    "                             P(('flac:title', 'LIKE', 'B%')))\n",
    "print(q)\n",
    "print(params)\n",
    "print('--')\n",
    "r = pd.read_sql(q, hs.conn, params=params)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_hashes_full(r['hash'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_sql('SELECT hash, title FROM Data WHERE title LIKE \"%Chimes%\"', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs.create_tag_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs.add_store('/media/wdm/magwitch/hashstash/data', 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_sql('SELECT media_type, count(hash) FROM Data GROUP BY media_type', hs.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag all the flacs\n",
    "#flac_shas = pd.read_sql('SELECT hash FROM Data WHERE media_type=\"audio/x-flac\"',\n",
    "#                        hs.conn)['hash']\n",
    "#for sha in flac_shas:\n",
    "#    print(sha)\n",
    "#    hs.add_tags(sha, flac_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag all the mp3\n",
    "#flac_shas = pd.read_sql('SELECT hash FROM Data WHERE media_type=\"audio/mpeg\"',\n",
    "#                        hs.conn)['hash']\n",
    "#for sha in flac_shas:\n",
    "#    print(sha)\n",
    "#    hs.add_tags(sha, mp3_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag all the mp4\n",
    "#shas = pd.read_sql('SELECT hash FROM Data WHERE media_type=\"audio/m4a\"',\n",
    "#                   hs.conn)['hash']\n",
    "#for sha in shas:\n",
    "#    print(sha)\n",
    "#    hs.add_tags(sha, mp4_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick_paths('SELECT hash, title FROM Data WHERE media_type=\"image/bmp\"',\n",
    "#            '/media/wdm/magwitch/hashstash/data').loc[0, 'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs.check_integrity_of_store('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lost file - file this in the stash!\n",
    "# 09997552-1EF0-4678-A86D-00E70BBBB6B1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
